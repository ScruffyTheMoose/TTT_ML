{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from TicTacToe import Board, GameTools as gt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the neural network multiclassifier model.\n",
    "\n",
    "This particular model has 3 hidden layers, with each layer containing 30 neurons. The activation function for the hidden layers is set to be ReLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = MLPClassifier(hidden_layer_sizes=(30, 30, 30), activation='relu')\n",
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating how to use the partial_fit() method.\n",
    "\n",
    "You must provide a matrix of features, an array of labels, and an array of all classes that your model may need to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0]]) # 2d array since features are always in a matrix format\n",
    "label = np.array([5])\n",
    "classes = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "agent.partial_fit(X=features, y=label, classes=classes)\n",
    "agent.loss_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that competes our agent against a random player.\n",
    "\n",
    "In order to keep this demonstration as simple as possible, we will build this training environment with as few settings as possible. You may want to consider adding additional parameters so you can adjust how your model interacts with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def environment(model: MLPClassifier, model_plays_first: bool, train_model: bool = False, print_board: bool = False):\n",
    "    game = Board() # initializing a new game of TTT\n",
    "    \n",
    "    match_states = list() # a list to store the state of the board for each play made by our model\n",
    "    match_labels = list() # a list to store the labels associated with each match state\n",
    "    alt_labels = list() # a list to store alternative labels for the case where our model loses\n",
    "    \n",
    "    status = game.status() # function specific to TTT. Will be used to check if the game has ended\n",
    "    \n",
    "    moves_remaining = 9\n",
    "    \n",
    "    # while loop which plays a game of TTT\n",
    "    while moves_remaining > 0 and not status[0]:\n",
    "        state = deepcopy(game.vector) # getting copy of the board state in a vectorized format - Ex: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "        label = None\n",
    "        \n",
    "        coords = gt.avail_moves(game.board) # using a tool specific to our TTT game to get the (row, column) coordinates for available positions on the board\n",
    "\n",
    "        matrix_state = np.array([state]) # putting our state into a numpy matrix. we need to use a consistent data structure and format for training the model and numpy works well\n",
    "        \n",
    "        # if model is playing first and it is first player's turn\n",
    "        # this is the model's move\n",
    "        if model_plays_first and moves_remaining % 2 != 0:\n",
    "            prediction = model.predict(matrix_state)[0] # predicting the best move based on the current game board\n",
    "            \n",
    "            move = ((prediction - 1) // 3, (prediction - 1) % 3) # converting an integer into (row, column) coordinates. This is specific to our TTT\n",
    "            \n",
    "            # it is possible the model will try to make a move that isn't possible because the space is taken. We will validate that the move was made successfully here.\n",
    "            out = game.move(row=move[0], column=move[1], player=1) # move() function returns True if move was successful, false otherwise\n",
    "            \n",
    "            if out:\n",
    "                label = prediction\n",
    "            else:\n",
    "                move = random.choice(coords) # choosing randomly from known available positions\n",
    "                coords.remove(move) # dropping our selected move from the available positions on the board\n",
    "                \n",
    "                label = (3 * move[0]) + move[1] + 1 # converting coordinates to integer value\n",
    "                game.move(row=move[0], column=move[1], player=1) # placing random move on the board\n",
    "                \n",
    "            match_states.append(state) # saving state\n",
    "            match_labels.append(label) # saving associated label\n",
    "            \n",
    "            if len(coords) > 0:\n",
    "                move = random.choice(coords)\n",
    "                pos = (3 * move[0]) + move[1] + 1\n",
    "                alt_labels.append(pos) # saving alternate label\n",
    "            else:\n",
    "                alt_labels.append(label) # there was no alternative because all other positions were taken\n",
    "        # if model is playing second and it is first player's turn\n",
    "        # this is the random players move\n",
    "        elif not model_plays_first and moves_remaining % 2 != 0:\n",
    "            move = random.choice(coords)\n",
    "            game.move(row=move[0], column=move[1], player=-1)\n",
    "        \n",
    "        # if model is playing first and it is the second player's turn\n",
    "        # this is the random players move\n",
    "        elif model_plays_first and moves_remaining % 2 == 0:\n",
    "            move = random.choice(coords)\n",
    "            game.move(row=move[0], column=move[1], player=-1)\n",
    "            \n",
    "        # if model is playing second and it is the second player's turn\n",
    "        # this is the model's move\n",
    "        else:\n",
    "            prediction = model.predict(matrix_state)[0] # predicting the best move based on the current game board\n",
    "            \n",
    "            move = ((prediction - 1) // 3, (prediction - 1) % 3) # converting an integer into (row, column) coordinates. This is specific to our TTT\n",
    "            \n",
    "            # it is possible the model will try to make a move that isn't possible because the space is taken. We will validate that the move was made successfully here.\n",
    "            out = game.move(row=move[0], column=move[1], player=1) # move() function returns True if move was successful, false otherwise\n",
    "            \n",
    "            if out:\n",
    "                label = prediction\n",
    "            else:\n",
    "                move = random.choice(coords) # choosing randomly from known available positions\n",
    "                label = (3 * move[0]) + move[1] + 1 # converting coordinates to integer value\n",
    "                game.move(row=move[0], column=move[1], player=1) # placing random move on the board\n",
    "                \n",
    "            match_states.append(state) # saving state\n",
    "            match_labels.append(label) # saving associated label\n",
    "            \n",
    "            if len(coords) > 0:\n",
    "                move = random.choice(coords)\n",
    "                pos = (3 * move[0]) + move[1] + 1\n",
    "                alt_labels.append(pos) # saving alternate label\n",
    "            else:\n",
    "                alt_labels.append(label) # there was no alternative because all other positions were taken\n",
    "        \n",
    "        moves_remaining -= 1\n",
    "        status = game.status()\n",
    "    # end of the while loop for playing a game of TTT\n",
    "    \n",
    "    # if our setting for training the model is set to True, then the model will be partially fit to the data from this game\n",
    "    # if set to false, this environment just allows a model to compete against a random player to evaluate performance\n",
    "    if train_model:\n",
    "        # converting our features, the match states, into a numpy matrix\n",
    "        features = np.array(match_states)\n",
    "        \n",
    "        # converting our labels into a numpy array\n",
    "        # if the model won, we use the winning labels\n",
    "        # if the model lost, we use the alternate labels\n",
    "        if status[1] != -1:\n",
    "            labels = np.array(match_labels)\n",
    "        else:\n",
    "            labels = np.array(alt_labels)\n",
    "        \n",
    "        # a list explicitly stating the possible classes for our model - a required parameter for partial fitting\n",
    "        classes = [x for x in range(1, 10)]\n",
    "        \n",
    "        # partially fitting the model to our data\n",
    "        model.partial_fit(features, labels, classes)\n",
    "    \n",
    "    # if print_board set to true, will print a nice string formatting version of the board\n",
    "    if print_board:\n",
    "        print(game.print())\n",
    "    \n",
    "    return status[1], match_states, match_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a fully functional training environment for our agent.\n",
    "\n",
    "We can run a single match without training and examine the output from our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = environment(model=agent, model_plays_first=True, train_model=False, print_board=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model is successfully playing a game of Tic Tac Toe! We can also see that our environment is able to successfully track all of the game states and decisions made by our model. This is good news!\n",
    "\n",
    "Now, we can iteratively train the model and then see how it performs. In this case, we set the model to only play as the second player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10000 training iterations\n",
    "for _ in range(10000):\n",
    "    t = environment(model=agent, model_plays_first=False, train_model=True, print_board=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our agent has now been trained on 10000 matches of TTT.\n",
    "\n",
    "We can ask our agent to predict the best move from a random board as a test of its functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_board = np.array([[0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "agent.predict(test_board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put our agent into matches against a random player and evaluate how the agent performs. Notice that the \"train_model\" parameter is set to \"False\". Our agent will strictly play, it will not learn.\n",
    "\n",
    "We will observe its performance when it plays first and when it plays second.\n",
    "\n",
    "Anything other than a win is considered a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_ct = 0\n",
    "loss_ct = 0\n",
    "\n",
    "for _ in range(5000):\n",
    "    f = environment(model=agent, model_plays_first=True, train_model=False, print_board=False)\n",
    "    \n",
    "    if f[0] == 1:\n",
    "        win_ct += 1\n",
    "    else:\n",
    "        loss_ct += 1\n",
    "    \n",
    "for _ in range(5000):\n",
    "    s = environment(model=agent, model_plays_first=False, train_model=True, print_board=False)\n",
    "\n",
    "    if s[0] == 1:\n",
    "        win_ct += 1\n",
    "    else:\n",
    "        loss_ct += 1\n",
    "        \n",
    "win_ct, loss_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we will want to save our agent as a binary file using the Pickle library. This will allow us to load our agent into whatever file we want for more training or to play the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(agent, open(\"model_binaries/demo_agent.sav\", \"wb\")) # saving the agent as a binary file\n",
    "\n",
    "loaded_agent = pickle.load(open(\"model_binaries/demo_agent.sav\", \"rb\"))\n",
    "loaded_agent.predict(test_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8f6c3ebd6a88d6aa92e8e216424c33c840aaeca7e1202db6e523f3cae8f4bb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
